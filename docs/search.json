[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "How to make use of AI?",
    "section": "",
    "text": "How to make use of AI?\n    \n  \n\n\n   WISDOM OF CROWDS   |  HYBRID INTELLIGENCE   |   DECISION SUPPORT   |   MACHINE LEARNING\n\n\n\n\n\n\n\n\n\n\nResearch\nHello. I am a final year PhD student at the Center for Adaptive Rationality, Max Planck Institute for Human Development. My work focuses on improving decision making of individuals, crowds and hybrid human-AI systems. I combine decision making research from psychology and economics with the latest insights from computer science.\n\n\nIndustry\nI also work as a consultant and ML engineer. Here, my focus is on the development of intepretable machine learning models that are accurate, fair and transparent. To that end, I employ a wide suite of model architectures and engage in a lot of feature engineering and multi-parameter optimization. In my industry work I often join forces with Simply Rational.\n\n\nLatest updates\n\n[09/24] Our work on LLMs and collective intelligence was published in Nature Human Behavior.\n[09/24] I was awarded a fellowship for interdisciplinary economics by the Joachim Herz Foundation for my work on improving consumers’ ability understand and make changes to their credit scores.\n[07/24] I presented my work on human-AI ensembling for efficient crowd wisdom at Advances in Decision Analysis 2024. Check out the project here.\n[06/24] We uploaded our pre-print on human-LLM ensembles and how their complementary strength improve open-ended differential diagnoses. Read it here.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "blog/template.html",
    "href": "blog/template.html",
    "title": "Analytical problem solving",
    "section": "",
    "text": "Unable to display PDF file. Download instead."
  },
  {
    "objectID": "projects/credit.html",
    "href": "projects/credit.html",
    "title": "Interpretable Credit Scores",
    "section": "",
    "text": "This project evaluated several credit scores in the lab and in the field WITH consumers. The scores we built to be accurate, fair and transparent.\nThis project is in cooperation with Germany’s largest credit scoring agency. Due to NDA and ongoing developments, public announcements and pre-prints of the research is not to be expected before May 2025.\nIf you want to know more, shoot me an email and we can have a chat.",
    "crumbs": [
      "Projects",
      "Interpretable Credit Scores"
    ]
  },
  {
    "objectID": "projects/hct.html",
    "href": "projects/hct.html",
    "title": "Hybrid Confirmation Trees",
    "section": "",
    "text": "Abstract: We study hybrid confirmation trees, a simple heuristic for producing hybrid intelligence in melanoma classification. Hybrid confirmation trees first elicit the decision of one human expert and one algorithm. Whenever the two agree a decision is immediately made. In case of disagreement, a second human expert is called in to break the tie. We apply this approach to data on skin cancer detection in dermoscopic and non-dermoscopic images across two studies. Study 1 establishes our approach to be a powerful alternative to human baselines, even outperforming up to three humans combined at lower costs. Study 2 compares hybrid confirmation trees against the industry-standard: humans taking AI advice. Crucially, we find humans supported by AI advice perform worse than hybrid confirmation trees. We attribute this benefit over human-only decision making and AI advice to uncorrelated errors between independent decisions by human and AI. AI advice lead to humans copying AI mistakes while hybrid confirmation trees already exhibit a generally lower agreement on AI mistakes, which can be successfully resolved by human tie breaking. Taken together, our results highlight the potential for combining independent choices of humans and AI for medical diagnostics and beyond as hybrid confirmation trees are a simple but powerful general-purpose method for arbitrating choices.",
    "crumbs": [
      "Projects",
      "Hybrid Confirmation Trees"
    ]
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Household debt and repayment behavior\n\n\nHow can we characterize debtors based on their behavior?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHybrid Confirmation Trees\n\n\nShould we rely on AI advice or rather combine indepenent human and AI decisions?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEfficient Crowds\n\n\nHow to use the wisdom of crowds more efficiently and improve decision making across 7 domains.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM-human ensembles\n\n\nCan we leverage complementary strengths of humans and LLMs in differential diagnoses?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow large language models can reshape collective intelligence\n\n\nHow could large language models influence collective intelligence?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretable Credit Scores\n\n\nBuilding consumer friendly credit scores. Field and lab evidence.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Projects"
    ]
  },
  {
    "objectID": "projects/crowd_stop.html",
    "href": "projects/crowd_stop.html",
    "title": "Efficient Crowds",
    "section": "",
    "text": "Abstract: Efficiently allocating individuals to work on complex decision problems is a key challenge for groups, organizations and societies, and requires navigating a crucial trade-off: increasing the number of individuals working on a task typically increases accuracy but at the expense of higher costs. Research in collective intelligence has proposed a plethora of mechanisms to pool the judgements of independent decision makers for increasing performance. However, these are all static and do not adjust the number of crowd members to the challenge at hand, resulting in high, fixed costs for every decision problem. We develop and test three decision rules that allow to benefit from the wisdom of the crowd adaptively depending on a case’s difficulty. Our rules rely on decision makers’ confidence judgements for stopping crowd growth. Empirical analyses in four real-world domains (cancer diagnoses, forecasting, false news classification, and criminology) using seven data sets find that our adaptive decision rules can achieve equal (or higher) accuracy compared to widely-used static crowd aggregators while using fewer individuals. Our findings present easily applicable decision guidelines ready to be employed in practice to substantially boost the efficiency of crowds.",
    "crumbs": [
      "Projects",
      "Efficient Crowds"
    ]
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog posts",
    "section": "",
    "text": "Analytical problem solving\n\n\nbased on causal, correlational and deductive models\n\n\n\nenglish\n\n\nmodeling\n\n\n\nI co-authored a peer-reviewed paper that compares the different modeling approaches for analytical problem solving. \n\n\n\n\n\nMar 2022\n\n\nDaniel Kapitan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "projects/LLM_humans.html",
    "href": "projects/LLM_humans.html",
    "title": "LLM-human ensembles",
    "section": "",
    "text": "Abstract: Artificial intelligence systems, particularly large language models (LLMs), are increasingly being employed in high-stakes decisions that impact both individuals and society at large, often without adequate safeguards to ensure safety, quality, and equity. Yet LLMs hallucinate, lack common sense, and are biased - shortcomings that may reflect LLMs’ inherent limitations and thus may not be remedied by more sophisticated architectures, more data, or more human feedback. Relying solely on LLMs for complex, high-stakes decisions is therefore problematic. Here we present a hybrid collective intelligence system that mitigates these risks by leveraging the complementary strengths of human experience and the vast information processed by LLMs. We apply our method to open-ended medical diagnostics, combining 40,762 differential diagnoses made by physicians with the diagnoses of five state-of-the art LLMs across 2,133 medical cases. We show that hybrid collectives of physicians and LLMs outperform both single physicians and physician collectives, as well as single LLMs and LLM ensembles. This result holds across a range of medical specialties and professional experience, and can be attributed to humans’ and LLMs’ complementary contributions that lead to different kinds of errors. Our approach highlights the potential for collective human and machine intelligence to improve accuracy in complex, open-ended domains like medical diagnostics.\nPREPRINT HERE"
  },
  {
    "objectID": "projects/debt.html",
    "href": "projects/debt.html",
    "title": "Household debt and repayment behavior",
    "section": "",
    "text": "We partner with coeo to investigate debtor behavior across 3.4 million debtors in Germany.\nResults are work in progress but you can shoot me an email and we talk about behavioral characteristics of people with varying amounts of debt and how to identify early warning signals of repayment struggles."
  },
  {
    "objectID": "projects/LLMxCI.html",
    "href": "projects/LLMxCI.html",
    "title": "How large language models can reshape collective intelligence",
    "section": "",
    "text": "Abstract: Collective intelligence underpins the success of groups, organizations, markets and societies. Through distributed cognition and coordination, collectives can achieve outcomes that exceed the capabilities of individuals—even experts—resulting in improved accuracy and novel capabilities. Often, collective intelligence is supported by information technology, such as online prediction markets that elicit the ‘wisdom of crowds’, online forums that structure collective deliberation or digital platforms that crowdsource knowledge from the public. Large language models, however, are transforming how information is aggregated, accessed and transmitted online. Here we focus on the unique opportunities and challenges this transformation poses for collective intelligence. We bring together interdisciplinary perspectives from industry and academia to identify potential benefits, risks, policy-relevant considerations and open research questions, culminating in a call for a closer examination of how large language models affect humans’ ability to collectively tackle complex problems.\nLINK\nCitation: Burton, J. W., Lopez-Lopez, E., Hechtlinger, S., Rahwan, Z., Aeschbach, S., Bakker, M. A., Berger, J., … & Hertwig, R. (2024). How large language models can reshape collective intelligence. Nature Human Behaviour.",
    "crumbs": [
      "Projects",
      "LLM and Collective Intelligence"
    ]
  }
]