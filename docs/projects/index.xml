<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Julian Berger | collective intelligence | wisdom of crowds | machine learning</title>
<link>julian-berger.github.io/projects/</link>
<atom:link href="julian-berger.github.io/projects/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.4.555</generator>
<lastBuildDate>Sun, 22 Sep 2024 14:30:10 GMT</lastBuildDate>
<item>
  <title>Hybrid Confirmation Trees</title>
  <link>julian-berger.github.io/projects/hct.html</link>
  <description><![CDATA[ 




<p>Abstract: We study hybrid confirmation trees, a simple heuristic for producing hybrid intelligence in melanoma classification. Hybrid confirmation trees first elicit the decision of one human expert and one algorithm. Whenever the two agree a decision is immediately made. In case of disagreement, a second human expert is called in to break the tie. We apply this approach to data on skin cancer detection in dermoscopic and non-dermoscopic images across two studies. Study 1 establishes our approach to be a powerful alternative to human baselines, even outperforming up to three humans combined at lower costs. Study 2 compares hybrid confirmation trees against the industry-standard: humans taking AI advice. Crucially, we find humans supported by AI advice perform worse than hybrid confirmation trees. We attribute this benefit over human-only decision making and AI advice to uncorrelated errors between independent decisions by human and AI. AI advice lead to humans copying AI mistakes while hybrid confirmation trees already exhibit a generally lower agreement on AI mistakes, which can be successfully resolved by human tie breaking. Taken together, our results highlight the potential for combining independent choices of humans and AI for medical diagnostics and beyond as hybrid confirmation trees are a simple but powerful general-purpose method for arbitrating choices.</p>
<p><img src="julian-berger.github.io/images/hct_1.png" class="img-fluid"></p>
<p><img src="julian-berger.github.io/images/hct_vs_advice.png" class="img-fluid"></p>



 ]]></description>
  <guid>julian-berger.github.io/projects/hct.html</guid>
  <pubDate>Sun, 22 Sep 2024 14:30:10 GMT</pubDate>
  <media:content url="julian-berger.github.io/images/hct_vs_advice.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Efficient Crowds</title>
  <link>julian-berger.github.io/projects/crowd_stop.html</link>
  <description><![CDATA[ 




<p>Abstract: Efficiently allocating individuals to work on complex decision problems is a key challenge for groups, organizations and societies, and requires navigating a crucial trade-off: increasing the number of individuals working on a task typically increases accuracy but at the expense of higher costs. Research in collective intelligence has proposed a plethora of mechanisms to pool the judgements of independent decision makers for increasing performance. However, these are all static and do not adjust the number of crowd members to the challenge at hand, resulting in high, fixed costs for every decision problem. We develop and test three decision rules that allow to benefit from the wisdom of the crowd adaptively depending on a case’s difficulty. Our rules rely on decision makers’ confidence judgements for stopping crowd growth. Empirical analyses in four real-world domains (cancer diagnoses, forecasting, false news classification, and criminology) using seven data sets find that our adaptive decision rules can achieve equal (or higher) accuracy compared to widely-used static crowd aggregators while using fewer individuals. Our findings present easily applicable decision guidelines ready to be employed in practice to substantially boost the efficiency of crowds.</p>
<p><img src="julian-berger.github.io/images/crowd_stop_Fig2.png" class="img-fluid"></p>



 ]]></description>
  <guid>julian-berger.github.io/projects/crowd_stop.html</guid>
  <pubDate>Sun, 22 Sep 2024 14:30:10 GMT</pubDate>
  <media:content url="julian-berger.github.io/images/crowd_stop_Fig2.png" medium="image" type="image/png" height="72" width="144"/>
</item>
<item>
  <title>Interpretable Credit Scores</title>
  <link>julian-berger.github.io/projects/credit.html</link>
  <description><![CDATA[ 




<p>This project evaluated several credit scores in the lab and in the field WITH consumers. The scores we built to be accurate, fair and transparent.</p>
<p>This project is in cooperation with Germany’s largest credit scoring agency. Due to NDA and ongoing developments, public announcements and pre-prints of the research is not to be expected before May 2025.</p>
<p>If you want to know more, shoot me an email and we can have a chat.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="julian-berger.github.io/images/credit.webp" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>



 ]]></description>
  <guid>julian-berger.github.io/projects/credit.html</guid>
  <pubDate>Sun, 22 Sep 2024 14:30:10 GMT</pubDate>
  <media:content url="julian-berger.github.io/images/credit.webp" medium="image" type="image/webp"/>
</item>
</channel>
</rss>
